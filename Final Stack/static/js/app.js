var scroll = new SmoothScroll('a[href*="#"]');

// var leaflet_analyst = [{"type": "Feature", "geometry": {"type": "Point", "coordinates": [-122.4194155, 37.7749295]}, "properties": {"Website": "LinkedIn", "Job_Title": "Summer 2019 Intern - Data Analytics Analyst", "Job_Description": "Job Category\nIntern\n\n\nJob Details\nSummer 2019 Intern - Data Analytics Analyst\n\nTeam Description\nThe Technology Communications & Readiness team at Salesforce is primarily responsible for preparing customers for technology, product, infrastructure, and system changes that will impact their Salesforce application, ensuring they are armed with all the relevant information, materials, and instructions to take any needed actions to accommodate those changes.\nYour Responsibilities\nPartner with teams to help develop hypothesis to drive data analysis to generate insights on the data\nDeliver Ad-hoc data analysis and/or Statistical analysis\nDevelop dashboards in Einstein Analytics to support analysis\nPartner with Data Engineers and Data Visualization Engineers\nBuild new mechanisms for data automation\n\nMinimum Qualifications\nPursuing a degree in Computer Science, Engineering, Information Systems, Business Analytics, Information Technology & Business or equivalent/related degree\nExperience with Development in BI software (ex. Tableau, Microstrategy, Einstein Analytics)\nWorking knowledge in at least one business intelligence tool such as MicroStrategy, Tableau or Business Objects\nProgramming experience in SQL, Python or R\nExperience with one or more database management tools Oracle, Postgres SQL, Amazon Redshift/RDS, etc.\nUnderstanding of data manipulation and database skills such as SQL with familiarity with ETL development process\n\nPreferred Qualifications\nStrong communication and visualization skills; can easily create powerful visualizations that transform complex data into easily-consumable, actionable insights\nMust be analytical, results driven, creative, innovative, self-motivated, proactive, organized, and be able to handle multiple projects simultaneously\nStrong technical skills with the ability to analyze issues, technical risks, and recommend permanent solutions to issues while still being able to communicate to non-technical users\nMust be detail oriented, organized, proactive mindset, can anticipate questions, automate answers to routine questions\n\n\nAbout Futureforce University Recruiting\nOur Futureforce University Recruiting program is dedicated to attracting, retaining and cultivating talent. Our interns and new graduates work on real projects that affect how our business runs, giving them the opportunity to make a tangible impact on the future of our company.\n\nWith offices all over the world, our recruits have the chance to collaborate and connect with fellow employees on a global scale. We offer job shadowing, mentorship programs, talent development courses, and much more.\n\n\n\n\nPosting Statement\n\nSalesforce.com and Salesforce.org are Equal Employment Opportunity and Affirmative Action Employers. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Headhunters and recruitment agencies may not submit resumes/CVs through this Web site or directly to managers. Salesforce.com and Salesforce.org do not accept unsolicited headhunter and agency resumes. Salesforce.com and Salesforce.org will not pay fees to any third-party agency or company that does not have a signed agreement with Salesforce.com or Salesforce.org.\nPursuant to the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, Salesforce will consider for employment qualified applicants with arrest and conviction records.3 hours ago ", "Company": "Salesforce", "Location": "San Francisco", "Skills_List": ["SQL", "Python", "Tableau"], "Job_Posting_URL": "https://www.indeed.com/jobs?as_and=data+analyst&as_phr=&as_any=&as_not=&as_ttl=data+analyst&as_cmp=&jt=all&st=&as_src=&salary=&radius=0&l=CA&fromage=any&limit=50&sort=date&psf=advsrch/rc/clk?jk=21aa273c187f645e&fccid=4027cfd917e1ee29&vjs=3", "Job_Scrape_Date": {"$date": 1540934660264}, "Posted_Days_Ago": "3 hours ago"}}, {"type": "Feature", "geometry": {"type": "Point", "coordinates": [-122.4194155, 37.7749295]}, "properties": {"Website": "Indeed", "Job_Title": "Data Analyst (Tableau/SQL)", "Job_Description": "Job Title: Data Analyst - Tableau/SQLClient: Large BankLocation: Uptown Charlotte or San Francisco, CADuration: 24 month contract, eligible for conversion to FTE***Applicants must be eligible to work a DISYS w2 without sponsorship. Student visas are not allowed by the client. No C2C***The manager is seeking an individual who is intellectually curious, willing to be hands-on, asks good questions, and is able work independently. Tableau and SQL knowledge are both essential to the role. Ideally, the candidate will have digital marketing data exposure, but this is not required. Teradata is the respective database utilized. Your responsibilities will include maintaining existing reports and creating ad-hoc reports. The dashboards are designed to monitor and optimize website marketing and email campaigns. Responsible for performing highly complex activities related to business analysis and/or modeling.Duties typically include providing insights, developing analytical strategies, performing analytical support and/or modeling regarding a wide array of business initiatives.This job requires application of analytical, statistical modeling, and forecasting methods.May focus on the theory and mathematics behind the analyses.Job Type: Full-time5 hours ago If you require alternative methods of application or screening, you must approach the employer directly to request this as Indeed is not responsible for the employer's application process.", "Company": "DISYS", "Location": "San Francisco", "Skills_List": ["SQL", "Tableau"], "Job_Posting_URL": "https://www.indeed.com/jobs?as_and=data+analyst&as_phr=&as_any=&as_not=&as_ttl=data+analyst&as_cmp=&jt=all&st=&as_src=&salary=&radius=0&l=CA&fromage=any&limit=50&sort=date&psf=advsrch/company/DISYS/jobs/Data-Analyst-8caed80025923dd7?fccid=2ac1f406582acd9b&vjs=3", "Job_Scrape_Date": {"$date": 1540934663152}, "Posted_Days_Ago": "5 hours ago"}}, {"type": "Feature", "geometry": {"type": "Point", "coordinates": [-121.8746789, 37.6624312]}, "properties": {"Website": "Indeed", "Job_Title": "Epic/Clarity data analyst with strong SQL and healthcare", "Job_Description": "Locals preferred, onsite interview mandatory.BS in Computer Science/Pharma or related field6-8 years genuine IT experience3-4 years experience working as Data Analyst.Healthcare data domain is required with knowledge of clinical.3+ years\u2019 Experience with Epic/clarity/ Big DataExperience with Big data is good to have.Strong analysis with PL SQL, database skills.Great attitude and approach working in a fast paced environmentJob Type: ContractExperience:data analysis, Healthcare domain, SQL, epic/clarity, bigdata: 10 years (Required)5 hours ago If you require alternative methods of application or screening, you must approach the employer directly to request this as Indeed is not responsible for the employer's application process.", "Company": "Xconic", "Location": "Pleasanton", "Skills_List": [], "Job_Posting_URL": "https://www.indeed.com/jobs?as_and=data+analyst&as_phr=&as_any=&as_not=&as_ttl=data+analyst&as_cmp=&jt=all&st=&as_src=&salary=&radius=0&l=CA&fromage=any&limit=50&sort=date&psf=advsrch/company/Xconic/jobs/Epic-Clarity-Data-Analyst-Strong-SQL-Healthcare-57cd69ec3dbabcfc?fccid=8ae989e05cc6d0cc&vjs=3", "Job_Scrape_Date": {"$date": 1540934666508}, "Posted_Days_Ago": "5 hours ago"}}, {"type": "Feature", "geometry": {"type": "Point", "coordinates": [-118.2436849, 34.0522342]}, "properties": {"Website": "Indeed", "Job_Title": "Analyst, Data & Merchandiser", "Job_Description": "Analyst, Data & Merchandiser\nCOTY, Professional Beauty\nCalabasas, CA\nDepartment: Sales\nDivision: COTY Professional Beauty\nFLSA Status: Non-Exempt\nLocation: Calabasas, CA\nPURPOSE\nOur purpose is to celebrate and liberate the diversity of beauty. We challenge convention through invention, expanding our horizons to enrich your reality with possibility. We build brands to inspire and enable our consumers to experience the confidence and joy of expressing their beauty, their way.\nMISSION AND RESPONSIBILITIES\nWe are actively looking for our future our future Data Analyst for Coty Professional Beauty. The Data Analyst will be responsible for a wide range of data management processes within the operations team. The goal is for this individual to assist with daily data maintenance through our various platforms and to identify data gaps, develop systemic solutions to these gaps, and update data accordingly to assist in the flow of professional beauty orders. This person must possess strong collaboration and analytical skills to independently drive results.\nResponsibilities:\nLead efforts for Master Data maintenance in Ecommerce platform, particularly around customer creation, data export, IDOC failure, credit card, and daily troubleshooting.\nProvide assistance with master data email ion for addressing concerns related to customer master data, material, and order issues.\nExecute data pulls using queries and tables in SAP, and update data accordingly using Windshuttle, LSMW, and XD99 mass data upload tools to align with key department KPIs.\nClose-out failed IDOCs, credits, and orders that have not yet Post Goods Issued (PGI\u2019d) in SAP as part of month-end and revenue recognition process. Identify root cause for data improvements in limiting scope of these non-PGI\u2019d orders.\nCapture key master data processes with the creation of standard job templates outlining execution steps needed to satisfy each task referencing SAP t-codes and other pertinent information.\nOversee eCommerce assortments and establish optimal product mix based on category goals, performance, and designated category roles\nOwn the online collections strategy execution and work with traffic drivers to ensure a great landing experience; manage homepage and landing page merchandising.\nBuilds and maintains category and brand pages; partner with Creative to build enhanced A+ details page\nCo-establish merchandising best practices.\nCoordinate with the team on new product launches\nAnalyze and present competitive intelligence to marketing planning, product merchandising and ecommerce; recommend ideas to merchandising teams based on data and competitive research.\nAdvocate for the needs of our customers and serve as the go-to person for insight on site traffic and merchandising performance; will combine an understanding of what drives e-commerce sales, and a passion for user experience to improve the onsite merchandising strategy\nServe as the subject matter expert on merchandising and traffic to a set of high traffic top-of-funnel experiences\nAnalyze site metrics and related data to identify opportunities to improve merchandising and the customer experience across the site and various product categories\nDevelop and implement strategies to drive sales and profitability; create methods to build conversion rates, page views per visitor, average order value, and lines per order\nEstablish eCommerce revenue and margin plans and forecasts for assigned categories using market, consumer, and competitive insights, and internal analysis\nPartner with the marketing team to draft creative briefs and create projects to maximize online merchandise presentation, developing category, theme or product-based landing pages\nEvaluate eCommerce category and key item performance and identify customer behavior and sales levels\nReviews website visitor feedback, and digital analytics to evaluate and optimize product details such as attributes, imagery, and videos to optimize sales online and traffic into stores\nEnsures the existing product catalogue is up to date with the latest released products, best-selling models, seasonal rotation and the marketing calendar.\nEngages with team daily to evaluate top/bottom selling styles and refine go-forward plan for site and marketing content.\nMonitor product pages in assigned categories to ensure content is accurate, current, and presented in to encourage purchases\nFinds and contributes to fixing possible bugs appearing on the existing product catalogue.\nPerform QA/maintenance of our site to ensure all offers, landing pages, product tiles and copy are accurate.\n\n\nTHE COTY IDEAL FIT\nDesired Qualifications:\nBachelor\u2019s degree BS Engineering (Computer, eCommerce, Supply Chain, Logistics, Business Administration, or similar discipline)\nDemonstrate ability to create and lead high performing teams to deliver team goals and\nresults. Demonstrate ability to lead and influence peers and hierarchy.\nAbility to work collaboratively across different styles. Develop strong partnerships. Must\nbe able to work well with people not physically collocated.\nAbility to communicate clearly, transparently, concisely, and on a timely basis with\nleadership. Comfortable with dealing with conflict, issue resolution and decisive decision\nStrong analytical ability, attention to detail, and organizational/time management skills.\nEffective oral and written communication skills.\nAptitude for problem solving and Goal oriented and results driven.\nProficient computer knowledge \u2013 MS Word, Excel spreadsheet and PowerPoint\nEqual Employment Opportunities\nWe offer equal employment opportunity to qualified individuals without regard to race, religion, color, national origin, age, gender, disability, sexual orientation, gender identity, gender expression, marital status, veteran status, or any other characteristic protected by law. We strongly believe that cultivating a diverse workplace gives a company strength. The combination of unique skills, abilities, experiences and backgrounds creates an environment that produces extraordinary results. EOE Minorities/Females/Protected Veterans/Disabled.\nEnglish - Please click on this link to review the Notification of Equal Opportunity Rights poster\nEspa\u00f1ol - Por favor, haga un clic en el enlace para revisar el poster de la Ley de los Derechos de Igualdad de Empeo2 hours ago ", "Company": "Coty Inc.", "Location": "Los Angeles", "Skills_List": ["Excel"], "Job_Posting_URL": "https://www.indeed.com/jobs?as_and=data+analyst&as_phr=&as_any=&as_not=&as_ttl=data+analyst&as_cmp=&jt=all&st=&as_src=&salary=&radius=0&l=CA&fromage=any&limit=50&sort=date&psf=advsrch/rc/clk?jk=2922d34df7ce0fee&fccid=7ad46606e93080a6&vjs=3", "Job_Scrape_Date": {"$date": 1540934669570}, "Posted_Days_Ago": "2 hours ago"}}, {"type": "Feature", "geometry": {"type": "Point", "coordinates": [-122.4194155, 37.7749295]}, "properties": {"Website": "Indeed", "Job_Title": "Data Analyst", "Job_Description": "Electric vehicle startup in downtown San Francisco (near BART) is hiring three data analysts for a new team. This is a high-visibility company and in an incredible position with new legislation supporting their growth. You will work alongside data scientists and be responsible for cross-functional responsibilities related to forecasting, visualization, and modeling.\nThis is a big name company at an exciting growth point \u2013 candidates with one to three years of professional analyst experience should apply!\nRequired Skills & Experience\nExperienced with SQL, Excel, etc.\nStrong communication, ability to interface with clients (data source)\nDesired Skills & Experience\nPython or R experience for statistical modeling and forecasting\nBI experience with Looker, Tableau, d3.js, Domo, or similar in-house visualization tool\nExperience working in a transportation/logistics environment\nLiving locally\nRoughly 1-3 years of professional analytics experience\nWhat You Will Be Doing\nAnalytics for one of three departments \u2013 Sales, Marketing, or Operations\nImproving business functions\nETL and visualization tasks to present to various leaders throughout the organization2 hours ago ", "Company": "Workbridge Associates", "Location": "San Francisco", "Skills_List": ["Excel", "Python", "d3", "Tableau", "R"], "Job_Posting_URL": "https://www.indeed.com/jobs?as_and=data+analyst&as_phr=&as_any=&as_not=&as_ttl=data+analyst&as_cmp=&jt=all&st=&as_src=&salary=&radius=0&l=CA&fromage=any&limit=50&sort=date&psf=advsrch/rc/clk?jk=afbd326cb73d0223&fccid=a6920e0a635e5c4e&vjs=3", "Job_Scrape_Date": {"$date": 1540934672452}, "Posted_Days_Ago": "2 hours ago"}}, {"type": "Feature", "geometry": {"type": "Point", "coordinates": [-95.8626886, 36.0895821]}, "properties": {"Website": "Indeed", "Job_Title": "Data Analyst I", "Job_Description": "Overview\nJoin the Commercial Analytics Team, a group of Business Analysts, Data Scientists and Data Analysts that support the Commercial Operations teams at Bio-Rad! We are looking for a Data Analyst to partner with the Sales and Marketing teams to extract data from our Salesforce and SAP systems, transform that data into meaningful information, and load that data into our data lake to help drive sales. The Data Analyst is responsible for using a broad range of technologies, analytical techniques and methodologies in order to retrieve and analyze a broad range of data from various sources to provide predictive insights and support business decision making.\nResponsibilities\nExtract, transform and load datasets (ETL) using R/ Python/ or SQL to support the creation of dashboards in Power BI.\nPerform data analyses using analytical models and mathematical analysis.\nUses data analysis/modeling to create new reports in Power BI; troubleshoots and modifies existing reports.\nAutomate report delivery where possible.\nPartners with team members in various business units and functions to support new and ongoing business reporting, analytical and training needs.\nResearches and prepares statistical reports. Consolidates information into cohesive and understandable written form for use in management decision-making.\nCoordinates with internal customers to develop reports that analyze spending, opportunities for consolidation and standardization.\nQualifications\nBachelor\u2019s degree or equivalent in Computer Science, Information Systems, or a related discipline.\n0-3 years\u2019 experience managing databases, providing timely user support, and writing reports, or equivalent combination of education and experience.\nWorking knowledge of ETL tools such as SQL, R, or Python.\nWorking knowledge of data visualization tools such as Micorsoft PowerBI, Tableau and GEP.\nStrong quantitative skills with proficiency in data analysis, modeling, and presenting.\nAbility to quickly learn new data models and functions.\nOperational knowledge of Sales and Marketing would be a plus.\nStrong interpersonal, organizational, analytical, problem solving, and time management skills.\nAbility to perform statistical reporting, including skill in composing logical, detailed, and analytical reports.\n\nAbout Bio-Rad:\n\nBio-Rad is a global leader providing a broad array of clinical diagnostics and life science research products. With a team of more than 7,800 employees and a global network of operations serving our customers, we help people live longer, healthier lives.\n\nBio-Rad was founded over six decades ago and has continued to provide the healthcare industry with innovative and useful products that help life science researchers accelerate the discovery process and medical diagnostic labs obtain faster, better results.\n\nEEO/AA Employer/Veterans/Disabled/Race/Ethnicity/Gender/Age\n\nAgency Non-Solicitation:\n\nBio-Rad does not accept agency resumes, unless the agency has been authorized by a Bio-Rad Recruiting Representative. Please do not submit resumes unless authorized to do so. Bio-Rad will not pay for any fees related to unsolicited resumes.6 hours ago ", "Company": "Bio-Rad", "Location": "Hercules", "Skills_List": ["SQL", "Python", "Tableau"], "Job_Posting_URL": "https://www.indeed.com/jobs?as_and=data+analyst&as_phr=&as_any=&as_not=&as_ttl=data+analyst&as_cmp=&jt=all&st=&as_src=&salary=&radius=0&l=CA&fromage=any&limit=50&sort=date&psf=advsrch/rc/clk?jk=894ab55664ead226&fccid=37b3a5500c2d9636&vjs=3", "Job_Scrape_Date": {"$date": 1540934675908}, "Posted_Days_Ago": "6 hours ago"}}, {"type": "Feature", "geometry": {"type": "Point", "coordinates": [-117.9143012, 33.8365932]}, "properties": {"Website": "Indeed", "Job_Title": "Data Analyst", "Job_Description": "Data AnalystAbout Us: mTAB helps market researchers gain insights from their survey data in our easy to use software platform. When our clients\u2019 data is messy, overwhelming, and complicated, they turn to us to make sense of it all. We\u2019re passionate about data and hope you are too.We think we\u2019ve got the best of both worlds: small company feel with large company stability. Although we\u2019re a relatively small company (under 50 employees), we\u2019re growing, profitable, and have a list of really big clients (e.g. Ford, GM, Taco Bell, GAP, to name a few). We\u2019re backed by a group of private investors who have big ambitions, including expanding our geographical presence and taking our software to the next level.About You: You have an analytic mindYou have advanced Microsoft Excel skills. You know how to use v-lookup and transpose data at the drop of a hat. Excel shortcuts? No problem!You have a Bachelor\u2019s degree in a quantitative field or related work experience.Your friends say that your organizational skills and attention to detail are impeccable.You work well under pressure and have the ability to meet deadlines.You\u2019re service-oriented and enjoy helping others (especially our clients!).PLUS but not required: Ability to speak and write in Mandarin or Japanese, Knowledge of SPSS, SAS, MS-SQL, or similar Business Intelligence software, and/or Experience in market research or data analytics.About the Job: You will be part of the team that is the \u2018special sauce\u2019 of our company.Amazing long term growth opportunity.You will transform customer research data into our own proprietary database format and make it ready for client side analysis.Analyze, interpret, and synthesize survey data to make it more actionable and impactful for stakeholders.Clearly express ideas, methodology, results, and recommendations through insightful reports to peers and management.You will troubleshoot and provide support to our clients on the phone and in writing.Details matter, so you will quality check our work to make sure that it consistently meets our high standards.Job Perks: Competitive salary at a profitable, stable, growing small companyA superb benefits package that includes health/dental/vision and generous employer retirement contributionA laid-back, awesome workplace with an endless supply of snacks/coffee/beer, frequent team lunches, and team events.Job Type: Full-timeLocation:Anaheim, CA 92801 (Preferred)Work authorization:United States (Required)7 hours ago If you require alternative methods of application or screening, you must approach the employer directly to request this as Indeed is not responsible for the employer's application process.", "Company": "mTAB LLC", "Location": "Anaheim", "Skills_List": ["Excel"], "Job_Posting_URL": "https://www.indeed.com/jobs?as_and=data+analyst&as_phr=&as_any=&as_not=&as_ttl=data+analyst&as_cmp=&jt=all&st=&as_src=&salary=&radius=0&l=CA&fromage=any&limit=50&sort=date&psf=advsrch/company/mTAB-LLC/jobs/Data-Analyst-265c9667a47a1236?fccid=8e81349964ad4b44&vjs=3", "Job_Scrape_Date": {"$date": 1540934678819}, "Posted_Days_Ago": "7 hours ago"}}, {"type": "Feature", "geometry": {"type": "Point", "coordinates": [-122.4194155, 37.7749295]}, "properties": {"Website": "Indeed", "Job_Title": "Data Systems Analyst", "Job_Description": "Having wide-ranging experience, applies data / information management concepts and campus / medical center / OP objectives to resolve issues, up to and including the most complex, with campus / medical center / OP-wide, institution-wide and / or multi-institutional impact. Formulates strategies and works on issues, up to and including the most complex, with little or no campus / medical center / OP precedent where analyses of situations, information or data requires an in-depth evaluation of variable factors. Selects methods, techniques and evaluation criteria to obtain results.\nInternal and external contacts often pertain to campus / medical center / OP plans and objectives. Is considered a subject matter expert at campus / medical center / OP and often recognized as an expert externally in the field or industry. Develops conceptual and logical data models with campus / medical center / OP-wide, institution-wide and / or discipline-wide scope. Support of UCSF Medical Center Clinical Systems including SOM, Campus, and Medical Center for all IBM and Linux systems, Storage Architecture, and backups.\nThe role is responsible for the following:\nAs primary design resource, provide expert level application infrastructure design and implementation skills set for the Medical Center datacenter and enterprise environments of UCSF\nLead Systems Architecture, Design, and implementation of multi-tenant systems including BCHO as well as understanding new products and technologies relationships with UCSF\nResearch and evaluate alternative technologies and architectures in relation to UCSF\u2019s infrastructure needs\nInterface with Management and vendors to develop and implement new solutions to meet business requirements\nPerform analytical, technical, cost analysis, and OPEX/CAPEX development work in the planning, design installation and on-gong administration and management of UCSF\u2019s Data Center network infrastructure\nLead design and roll out of efforts on design/deployment of large enterprise wide projects and IT infrastructure initiatives having significant enterprise-wide impact\nParticipate in highest level of escalation from level two and three support and troubleshooting staff in resolving problems with UCSF Medical Center systems\nParticipate on on-call duties and will work some evenings, weekends, and holidays as required in support of UCSF initiatives\nWork collaboratively in a cross-functional environment with UCSF\u2019s security and network engineering teams to identify system risks and issues and create plans to mitigate and resolve them\nDevelop Capacity planning and management reports\nResponsible and accountable for overall Epic database management for all UCSF Health campuses\nProvides direct supervision to professionals or skilled technical employees\nFunctioning with minimum level of supervision, the incumbent in this role is expected to take ownership of projects and other duties as assigned by the CTO\n\nRequired Qualifications\n\n\nTen years experience with Unix/Linux systems\nFive to seven years experience with Enterprise storage arrays\nEpic certification\nUnix certification\nStorage certification\nBachelor's degree in related area and / or equivalent experience / training\nEpic certification Cache DBA\nExpert level understanding of modern enterprise system, storage, and applications by using standards and technologies including but not limited to: AIX, Linux, Fiber, FCoE, Ethernet, Cache, TCP/IP\nExpert level understanding of system servers, storage, and application architectures consisting of converged systems, compute, storage and networking platforms\nIn-depth knowledge of complex system technologies from multiple storage, server, and application vendors\nIn-depth knowledge, skills and experience with AIX, Linux, SVC, Storage, and multiple application and os platforms\nIn-depth knowledge, skills and experience with configuration and setup of multi-vendor systems\nWorking knowledge of storage allocation and configuration to applications and servers\nKnowledge of cross functional support of OS, storage, and applications\nStrong documentation skills with the ability to present to non-technical audiences\nStrong professional, verbal, written and presentation skills\nAbility to act as a consultant in the areas of planning, advising and implementing server, storage, and application concepts and architectures.\nStrong experience with management tools, technologies and products\nAbility to work days, evenings, and weekends as required: 24x7 support and professionally respond to urgent situation during non-standard hours with short or not notice\nThe flexibility to orient and work at all UCSF Medical Center locations\n\nPreferred Qualifications\n\n\nN/A\n\nLicensure/Certification\n\n\nEpic certification\nUnix certification\nStorage certification\n\nLiving Pride Standards\n\n\nService Excellence\nDemonstrates service excellence by following the Everyday PRIDE Guide with the UCSF Medical Center standards and expectations for communication and behavior. These standards and expectations convey specific behavior associated with the Medical Center\u2019s values: Professionalism, Respect, Integrity, Diversity and Excellence, and provide guidance on how we communicate with patients, visitors, faculty, staff, and students, virtually everyone, every day and with every encounter. These standards include, but are not limited to: personal appearance, acknowledging and greeting all patients and families, introductions using AIDET, managing up, service recovery, managing delays and expectations, phone standards, electronic communication, team work, cultural sensitivity and competency.\nUses effective communication skills with patients and staff; demonstrates proper telephone techniques and etiquette; acts as an escort to any patient or family member needing directions; shows sensitivity to differences of culture; demonstrates a positive and supportive manner in which patients / families/ colleagues perceive interactions as positive and supportive. Exhibits team work skills to positively acknowledge and recognize other colleagues, and uses personal experiences to model and teach Living PRIDE standards.\nExhibits tact and professionalism in difficult situations according to PRIDE Values and Practices\nDemonstrates an understanding of and adheres to privacy, confidentiality, and security policies and procedures related to Protected Health Information (PHI) or other sensitive and personal information.\nDemonstrates an understanding of and adheres to safety and infection control policies and procedures.\nAssumes accountability for improving quality metrics associated with department/unit and meeting organizational/departmental targets.\nWork Environment\nKeeps working areas neat, orderly and clutter-free, including the hallways. Adheres to cleaning processes and puts things back where they belong. Removes and reports broken equipment and furniture.\nPicks up and disposes of any litter found throughout entire facility.\nPosts flyers and posters in designated areas only; does not post on walls, doors or windows.\nKnows where the Environment of Care Manual is kept in department; corrects or reports unsafe conditions to the appropriate departments.\nProtects the physical environment and equipment from damage and theft.\nThe flexibility to orient and work at all UCSF Medical Center locations is required.\n\n\nEqual Employment Opportunity\n\n\nThe University of California San Francisco is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran or disabled status, or genetic information. Further information about the University of California, San Francisco, is available at diversity.ucsf.edu. UCSF seeks candidates whose skills, and personal and professional experience, have prepared them to contribute to our commitment to diversity and excellence, and the communities we serve.9 hours ago ", "Company": "University of California San Francisco Medical Center", "Location": "San Francisco", "Skills_List": ["Excel", "Bachelors"], "Job_Posting_URL": "https://www.indeed.com/jobs?as_and=data+analyst&as_phr=&as_any=&as_not=&as_ttl=data+analyst&as_cmp=&jt=all&st=&as_src=&salary=&radius=0&l=CA&fromage=any&limit=50&sort=date&psf=advsrch/rc/clk?jk=3cc9ecb3dc43840b&fccid=945ef85720cdacd0&vjs=3", "Job_Scrape_Date": {"$date": 1540934681837}, "Posted_Days_Ago": "9 hours ago"}}, {"type": "Feature", "geometry": {"type": "Point", "coordinates": [-122.1560768, 37.7249296]}, "properties": {"Website": "Indeed", "Job_Title": "Equipment Data Analyst", "Job_Description": "At Peterson our Vision is to be our customers\u2019 first choice. We put our customers first and continually strengthen our partnerships through our employee\u2019s hard work, ingenuity and determination. Our 80 year history is a reflection of our collective efforts and focus.\n\nWe provide a family oriented environment that promotes safety, personal growth and professional achievement. Critical to our continued success is hiring and developing exceptional employees. We are deeply committed to providing an environment necessary to attract and retain engaged employees who will relentlessly strive to reach Peterson\u2019s strategic goals and vision. We have high standards for our employees, with good reason. They represent Peterson, our family, our brand, and our values to customers and our team members.\n\nWhy Peterson?\nWe have high expectations and so do you. You are exceptionally motivated, have outstanding skills, and are looking for more than just a job. We offer competitive wages, generous benefits, and promotional opportunities at a family owned and operated business that really cares about employees. If you want to work side-by-side with others who are passionate about customer service, consider joining our team. You can help us write more chapters in our success story as we move towards celebrating our 100 year anniversary.\n\n\nResponsibilities\nThe person in the position organizes and performs Machines\u2013Engines Inventory/Population data cleanup and maintenance in DBS-OLGA-ED-CRM for all Peterson CAT locations (CA and OR). Responsible to review and perform monthly cleanup and update duties for all DBS-OLGA-ED-CRM (Dealer-Business Systems - Opportunity Lead Generation Analyzer \u2013 Equipment Data) specific system maintenance and reports. Responsible to update customers\u2019 Machines-Engines population records as requested by Product Support Reps, Machines-Engines Salesman and Sales Managers and other Peterson CAT employees as defined by the Product Support Programs Supervisor.\n\nWorks under the direction of the Product Support Programs Supervisor to perform duties in cleaning up and maintaining Customers\u2019 Equipment Population records (Machines-Engines) with valid and accurate data.\nCommunicates on a daily/weekly basis, with Product Support Programs Supervisor to resolve issues or problems related to Machines and Engines Customers\u2019 inventory-population record accuracy and updates; and on a monthly basis resolve issues and problems in relation to error and exception reports.\nPrepare and create analysis/reports, presentations, graphs and other analysis reports on Equipment data; including CAT, non-CAT, T200 for customers and machines\nPrepare and create analysis/reports, presentation, graphs and other analysis report on OLGA and COGNOS including; Opportunity, Sales, Lost Opportunities, POPS and POLS, and all related subjects found in OLGA web reports.\nUpdates guidelines and other reference material for DBS, ED (Equipment Data) and other systems manuals/guidelines\nWorks directly or indirectly, as defined by the Product Support Programs Supervisor with Product Supports Reps, Machines-Engines Salespeople and Sales Managers and other Peterson CAT employees to update customer\u2019s machines-engines inventory/population records.\nOrganizes data and performs cleanup duties for the following OLGA reports and configurations:\nOpportunity/Sales\nPast And Future Opportunity\nCustomer Exclusion Report\nDuplicate Serial Number Report\nParked Equipment Conflict Report\nProcessing Errors\nCalculations Errors\nData Errors\nConfigurations\nBranch Stores\nGeneric Parts\nLabor Rates\nSource Supply Codes\nExclusions and Inclusions\nCRM Exports\nDealer Parts\nDealer BUILDER File Upload\nBUILDER Files\nCustomer\u2019s Equipment Population Maintenance\nRemove or Add units - Equipment that have been sold, no longer in service or purchased\nUpdate prime product record - Equipment\u2019s units that are \u201cout of territory\u201d or will be parked for extended periods of time\nVerify-Update Customer\u2019s Population unit accuracy\nEquipment Population accuracy\nSerial Number\nDisplay Model\nPrincipal Work Code\nApplication Code\nYear of Manufacture\nAnnual Hours\nCustomer Assigned Industry Segment\nCustomer Assigned Store\nAnd, other information as requested-needed\nCustomer-Equipment Association Information:\nVerify association between Customer and Equipment\nPerform Customer Inclusion/Exclusion in and from OLGA\nCustomer/Equipment accuracy between DBS and OLGA\nMaintains punctual, regular, and predictable attendance.\nRespectfully takes direction from supervisor/ manager.\nQualifications\nAssociate's degree (A. A.) or equivalent from two-year College or technical school; and at least two years of work experience with data analysis and inputs; or equivalent combination of education and experience.\n\nExperience with DBS, CAT Machines-Engines Equipment database and Tableau knowledge is strongly preferred. Knowledge and working experience with Microsoft Office (Excel-Word-PowerPoint) programs is a requirement.\n\nPeterson Holding Company is committed to equal employment opportunity and affirmative action. Minorities, females, veterans, and individuals with disabilities are encouraged to apply. A drug screen and background check is required.6 hours ago ", "Company": "Peterson Caterpillar", "Location": "San Leandro", "Skills_List": ["Excel", "Tableau"], "Job_Posting_URL": "https://www.indeed.com/jobs?as_and=data+analyst&as_phr=&as_any=&as_not=&as_ttl=data+analyst&as_cmp=&jt=all&st=&as_src=&salary=&radius=0&l=CA&fromage=any&limit=50&sort=date&psf=advsrch/rc/clk?jk=b9329f5e76792009&fccid=2e9ff80da5eda362&vjs=3", "Job_Scrape_Date": {"$date": 1540934685041}, "Posted_Days_Ago": "6 hours ago"}}, {"type": "Feature", "geometry": {"type": "Point", "coordinates": [-122.1817252, 37.4529598]}, "properties": {"Website": "Indeed", "Job_Title": "Space Data Analyst", "Job_Description": "JLL Associate, Occupancy Plannning: Space Data Analyst (Planning, CAD, CAFM, BIM),\n\nDedicated on-site with Client in Menlo Park, CA.\nSupport the global CAD/CAFM team with various space data management and test fit planning workflow.\nSystematically gather, organize, and manage as-built documentation for the global real estate portfolio.\nPoint of contact for drawings, BIM models, and space data.\nManage and maintain space data information using Revit, AutoCAD, PlanGrid, and other internal tools.\nSupport internal teams and remote office leads with floor plan updates, test fits, and related design documentation.\nProduce BIM models that reflect global standards.\nLiaise between CAFM team and internal FB teams to support multiple project initiatives.\n\n\n\n\n\nJLL Privacy Statement\nWhen you visit JLL websites, JLL may collect information related to those visits, without you actively sending that information. This information may include, for example, the internet browser you are using, your access device\u2019s operating system, the language in which that system presents information to you, your IP (Internet Protocol) address, the web search that took you to the JLL website, the web pages and advertisements displayed to you, and the links you click on.\n\nFor additional details please see JLL's Global Privacy Statement or our career site pages for each country.\n\nFor employees in the United States, please see a fully copy of our Equal Employment Opportunity and Affirmative Action policy here .8 hours ago ", "Company": "JLL", "Location": "Menlo Park", "Skills_List": [], "Job_Posting_URL": "https://www.indeed.com/jobs?as_and=data+analyst&as_phr=&as_any=&as_not=&as_ttl=data+analyst&as_cmp=&jt=all&st=&as_src=&salary=&radius=0&l=CA&fromage=any&limit=50&sort=date&psf=advsrch/rc/clk?jk=61e34f64245fb93f&fccid=9917de3c28f569f6&vjs=3", "Job_Scrape_Date": {"$date": 1540934688294}, "Posted_Days_Ago": "8 hours ago"}}];
// var leaflet_scientist = [{"type": "Feature", "geometry": {"type": "Point", "coordinates": [-122.4194155, 37.7749295]}, "properties": {"Website": "Indeed", "Job_Title": "Data Scientist - Risk", "Job_Description": "THE CHALLENGE\nEventbrite is big, bustling marketplace where anyone can post an event in minutes or buy a ticket in seconds. The Fraud and Trust & Safety teams make sure that all of that goes smoothly. Our organizers get paid, and our attendees find great experiences. That happens reliably even as we launch innovative features and expand into new markets across the world. Our Data Scientists ensure we keep up without our organizers knowing even we\u2019re there by designing low profile, high precision solutions to the ever-changing landscape of threats.\n\nTHE TEAM\nThe Risk and Trust & Safety group is a small, high performing, multi-disciplinary team ranging from chargeback specialists and fraud analysts to data scientists and engineers, all working toward the common goal of keeping Eventbrite users safe. We expect everyone to be vigilant for emerging problems and innovative solutions. We expect high quality contributions from every team member. And we expect even more in terms of supporting each other to make that happen.\n\nTHE ROLE\nYou\u2019ll make sure the right needle gets pulled out of the right haystack every time by developing high precision fraud and spam detection algorithm. You\u2019ll work with our fraud and trust experts to understand all the nitty gritty details of what\u2019s working well and where we need to fill gaps. You\u2019ll leverage our in house decisioning platform to quickly test, improve, ship, and track models. And you\u2019ll collaborate closely with our dedicated engineering team to make sure your solution makes it from the lab to the field exactly the way you envisioned.\n\nTHE SKILL SET\nFluency with machine learning and data mining techniques and concepts\nProven ability to craft and track complete solutions to real world problems using statistical methods\nAbility to succinctly and accurately explain a complex solution to any audience\nStrong experience with data processing in Python (>2 years)\nComfort with SQL and an ability using it to make sense out of messy data (>2 years\nAdvanced Degree in Relevant Field\nBONUS POINTS\nUnderstanding of big data processing technologies like spark, hive, or presto\nPractical experience in risk, spam, payments or related topics\nActive Eventbrite user with a passion for live events\n\nABOUT EVENTBRITE\nEventbrite is the world\u2019s leading event technology platform, powering more than two million live experiences each year. We build technology that allows anyone to create, share, find and attend events of all kinds. Music festivals, marathons, conferences, hackathons, political rallies, fundraisers, gaming competitions\u2014 you name it, we power it. Meet some of the team.\n\nIS THIS ROLE NOT AN EXACT FIT?\nSign up to keep in touch and we\u2019ll let you know when we have new positions on our team.\n\nEventbrite is a proud equal opportunity/affirmative action employer supporting workforce diversity. We do not discriminate based upon race, ethnicity, ancestry, citizenship status, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), marital status, registered domestic partner status, caregiver status, sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, genetic information, military or veteran status, mental or physical disability, political affiliation, status as a victim of domestic violence, assault or stalking, or other applicable legally protected characteristics.\n\nFLSA Status: Exempt\n\nPursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records\n\nApplicant Privacy Notice5 hours ago ", "Company": "Eventbrite", "Location": "San Francisco", "Skills_List": ["SQL", "Python", "Machine Learning"], "Job_Posting_URL": "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=data+scientist&as_cmp=&jt=all&st=&as_src=&salary=&radius=0&l=CA&fromage=any&limit=50&sort=date&psf=advsrch/rc/clk?jk=d315378a2b0afca6&fccid=28dd3b780624bbf1&vjs=3", "Job_Scrape_Date": {"$date": 1540934618387}, "Posted_Days_Ago": "5 hours ago"}}, {"type": "Feature", "geometry": {"type": "Point", "coordinates": [-121.8399593, 37.2488478]}, "properties": {"Website": "Monster", "Job_Title": "Data Scientist , Universal Media", "Job_Description": "Summary\nPosted: Oct 30, 2018\n\nRole Number: 200005499\nApple Universal Media is seeking an outstanding lead Data Scientist to drive the next generation knowledge graph powering Apple\u2019s Media and Sports discovery. At Apple, phenomenal ideas have a way of becoming phenomenal products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish.\nKey Qualifications\nKey Qualifications\nBring your 7+ Years industry experience working with Data Science to our team\nYou have hands-on experience with NLP, mining of structured, semi-structured and unstructured data\nYou have a rich history of crafting new solutions to evolving problems\nYou bring an affinity for Apple Media Products and digital content, in general.\nYou enjoy paying attention to details almost as much as the big technical wins\nYou are passionate about working with large scale data sets\nYou bring experience with Solr/ Lucene, Cassandra and related technologies\nYou have experience with machine learning tools and libraries such as Spark\nYou have an intuitive understanding of machine learning algorithms, supervised and unsupervised modeling techniques\nYou are highly technical, detail-oriented, creative, motivated, and focused on achieving results.\nYou are excited about reaching millions of users across our many platforms\nYou share our obsession with quality\nWe value your strong interpersonal skills as well as experience driving decisions across diverse organizations\nYou love collaborating under tight deadlines and tackles problems with imaginative and elegant solutions.\nYour creative problem solving skills will be utilized daily\nYou\u2019ll work with a team of engineers who are passionate about building new technologies and tools\nDescription\nDescription\nWe offer an excellent opportunity for an Applied Data Scientist to join the Universal Media Team. You will chartered with building a comprehensive knowledge graph for powering Apple's TV App, Siri, Safari search and discovery services across all Apple platforms. You are a self starting, energetic individual with excellent interpersonal skills to effectively collaborate with all levels of the organization. We provide an environment where you will take ownership of projects that focus on topics such as classification, attribute ranking, filtering, mapping or enriching of entity records or their data. You will have the opportunity to implement standard and proprietary algorithms for handling and processing data. You will use distributed data processing and analysis methodologies. You will work alongside other cross-functional teams closely, in order to bring the best customer experiences to life. Be a part of an innovative, impactful team making a difference to customer's relationship with Apple products.\nEducation & Experience\nEducation & Experience\nMasters or PhD in Computer Science, Statistics or related field or equivalent experience\nAdditional Requirements\nAdditional Requirements\nGreat to Have - Server side Java development experience Experience Ranking entities or attributes Experience with Catalogs generation and Mapping techniques Knowledge of Graph databases Multimodal learning application2 hours ago ", "Company": "Apple", "Location": "Santa Clara Valley", "Skills_List": ["Excel", "Java", "Machine Learning", "Masters", "PhD"], "Job_Posting_URL": "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=data+scientist&as_cmp=&jt=all&st=&as_src=&salary=&radius=0&l=CA&fromage=any&limit=50&sort=date&psf=advsrch/rc/clk?jk=3a01fe4e42c2580a&fccid=c1099851e9794854&vjs=3", "Job_Scrape_Date": {"$date": 1540934621766}, "Posted_Days_Ago": "2 hours ago"}}, {"type": "Feature", "geometry": {"type": "Point", "coordinates": [-122.4194155, 37.7749295]}, "properties": {"Website": "Indeed", "Job_Title": "Sr. Data Scientist", "Job_Description": "We are looking for a Data Scientist to analyze large amounts of raw information to find patterns that will help improve the apartment rental experience. We will rely on you to extract valuable business insights and help apply them to product and process.\nIn this role, you should be highly analytical with a knack for analysis, math and statistics. Critical thinking and problem-solving skills are essential for interpreting data. We also want to see a passion for machine-learning and research.\nYour Responsibilities: \u2022Collaborate with engineering and product development teams \u2022Identify valuable data sources and automate collection processes \u2022Present information using data visualization techniques \u2022Do ad-hoc analysis and presenting results in a clear manner \u2022Build predictive models and machine-learning algorithms \u2022Process, clean, and verify the integrity of data used for analysis \u2022Create automated anomaly detection systems \u2022Develop internal A/B testing procedures \u2022Automate scoring using machine learning techniques\nSkills and Qualifications: \u20225+ years experience as a Data Scientist or Data Analyst \u2022Analytical mind and business acumen \u2022Great communication skills \u2022Data-oriented personality \u2022Good applied statistics skills, such as distributions, statistical testing, regression, etc. \u2022Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc. \u2022Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc \u2022Experience with data visualisation tools, such as D3.js , GGplot, etc. \u2022Proficiency in using query languages such as SQL, Hive, Pig \u2022Python, Tensor Flow, Keras, Theano, nltk, pandas, scipy, sk-learn, etc\nBonus Skills: \u2022Snowflake \u2022Mode \u2022Fivetran \u2022Postgres / Postgrs (good understanding of SQL if not Postgres) \u2022AWS \u2022Scrapy \u2022Excel / Google Sheets \u2022Django\nBenefits & Perks\n\nFull healthcare, dental, vision benefits \u2022401k plan \u2022Flexible vacation policy; work hard and take time when you need it \u2022$150/month in gym/commuter credits \u2022HQ catered meals, unlimited coffee, snacks and beverages \u2022HQ team retreats every quarter \u2022HQ team sports (soccer, dodgeball, and more) \u2022HQ team happy hours \u2022Weekly looks at all major company metrics \u2022Shiny new laptop of your choosing\n\nPlease note: Zumper does not accept unsolicited resumes from staffing vendors, including recruitment agencies and/or search firms. Please do not forward resumes to our jobs alias, Zumper employees, or any other company location. Any submittals without a prior signed agreement will become property of Zumper.\nPlease note: Zumper does not accept unsolicited resumes from staffing vendors, including recruitment agencies and/or search firms. Please do not forward resumes to our jobs alias, Zumper employees, or any other company location. Any submittals without a prior signed agreement will become property of Zumper.3 hours ago ", "Company": "Zumper", "Location": "San Francisco", "Skills_List": ["Excel", "SQL", "Python", "pandas", "d3", "Machine Learning"], "Job_Posting_URL": "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=data+scientist&as_cmp=&jt=all&st=&as_src=&salary=&radius=0&l=CA&fromage=any&limit=50&sort=date&psf=advsrch/rc/clk?jk=fa5e916a18f95515&fccid=68b09cbcad949ffc&vjs=3", "Job_Scrape_Date": {"$date": 1540934624703}, "Posted_Days_Ago": "3 hours ago"}}, {"type": "Feature", "geometry": {"type": "Point", "coordinates": [-118.530123, 34.2381251]}, "properties": {"Website": "Indeed", "Job_Title": "Scientist 1, Data", "Job_Description": "Aret\u00e9 Associates seeks highly motivated, technically talented and intellectually agile individuals to perform challenging and important work in the areas of signature discovery and exploitation algorithms; detection, classification and tracking algorithms; and design, analysis and performance optimization of robust, real-world advanced analytics software solutions.\n\nThe Data Analytics group at Aret\u00e9 has position openings for entry- to mid-level data scientists at our headquarters in Northridge, California.\n\nResearches, designs, develops and verifies signal and image collection systems, and defines and develops processing and dissemination computer algorithms. Develops requirements analysis, system architecture, and integrates new signal and image capture and processing technology systems. Designs, develops and analyzes systems for the extraction of information from sensors. Systems utilization includes implementation of signal and image processing with advanced computer architectures.\n\nRoles and Responsibilities:\n\nConceive, design, prototype and implement advanced algorithms aimed at generating solutions to critical problems\n\nAssess algorithm performance on real-world data\n\nSupport multiple projects throughout the company\n\nEngage customers and collaborators to provide technical results and recommendations\n\nDocument results via written reports, briefings and well-commented code\n\nRequired Qualifications:\n\nBachelor\u2019s, Master\u2019s degree in physical sciences, engineering, or mathematics with 0-4 years\u2019 experience\n\nAbility to quickly pick up \u201con the fly\u201d new skills and develop expertise necessary to provide the best possible solution\n\nExperience in scientific programming using Python, C++, Matlab, or similar high-level languages\n\nExcellent interpersonal communications, technical writing, and briefing skills\n\nAbility to work with minimal supervision and collaborate on small teams\n\nAgility to work multiple potentially disparate projects simultaneously\n\nProven capability to develop creative solutions to complex technical problems\n\nIntellectual curiosity and high motivation to solve challenging problems\n\nU.S. citizenship and ability to acquire a security clearance\n\nDesired Qualifications:\n\nExperience in any of the following areas: machine learning, including artificial intelligence and deep learning; data analysis, statistical signal processing, spectroscopy, bioinformatics, data fusion, natural language processing, algorithm development\n\nExperience with the Department of Defense (DoD) or the Intelligence Community (IC)\n\nCurrent security clearance\n\nAret\u00e9 Associates offers an excellent compensation and a full benefits package. U.S. citizenship, background screen and drug test are required to meet position eligibility. Please submit your resume on-line at: http://www.arete.com\n\nAret\u00e9 Associates is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex including sexual orientation and gender identity, national origin, disability, protected Veteran Status, or any other characteristic protected by applicable federal, state, or local law.\n\nIf you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Arete Associates Human Resources Representative.\n\nAret\u00e9 will consider for employment-qualified applicants with criminal histories in a manner consistent with the requirements of the Los Angeles Fair Chance Initiative for Hiring.\nBack Share\nApply Now3 hours ago ", "Company": "Aret\u00e9 Associates", "Location": "Northridge", "Skills_List": ["Excel", "Python", "Machine Learning"], "Job_Posting_URL": "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=data+scientist&as_cmp=&jt=all&st=&as_src=&salary=&radius=0&l=CA&fromage=any&limit=50&sort=date&psf=advsrch/rc/clk?jk=b9e8413bb90fe340&fccid=0e3cd51e3eb73b6b&vjs=3", "Job_Scrape_Date": {"$date": 1540934628041}, "Posted_Days_Ago": "3 hours ago"}}, {"type": "Feature", "geometry": {"type": "Point", "coordinates": [-118.2436849, 34.0522342]}, "properties": {"Website": "Indeed", "Job_Title": "Sr. Data Scientist", "Job_Description": "Join Taboola's Big Data team as a Sr. Data Scientist!\n\nRead something interesting online to day? There's a good chance it reached you because of our technology.\n\nTaboola is the world's leading content discovery platform, serving 360B recommendations to over 1B unique visitors each month on the web's most innovative publisher sites, including NBC, USA Today, The Weather Channel, Tribune and Fox Sports.\n\nAbout You: You are a hyper-intelligent Data Scientist with a robust background in a big data environment.\n\nIn this Job: You will build complex Data Science solutions for large-scale product initiatives, scaling up to a Petabyte of data.\n\nRequirements:\n\n3+ years of experience as a Data Scientist, preferably in Big Data Environment\n2+ years of programming experience in Java/Scala and/or Python\nHadoop stack (HIVE, Pig, Hadoop streaming) and MapReduce\nHBase or comparable NoSQL\nSQL & database experience\nExperience with Google products: Google Cloud Storage, Google Analytics and Google Big Query (a plus)\nBachelor\u2019s degree in quantitative or related field\nResponsibilities:\n\nDesign and build predictive customer behavior models for targeting and personalization\nImplement Machine Learning and statistics-based algorithms for prediction and optimization, then deliver to production\nBuild and maintain code to populate HDFS, Hadoop with log from Kafka or data loaded from SQL production systems\nDesign, build and support algorithms of data transformation, conversion, computation on Hadoop, Spark and other distributed Big Data Systems\n#LI - AM1\n\n#GD2 hours ago ", "Company": "Taboola", "Location": "Los Angeles", "Skills_List": ["SQL", "Python", "Java", "Machine Learning"], "Job_Posting_URL": "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=data+scientist&as_cmp=&jt=all&st=&as_src=&salary=&radius=0&l=CA&fromage=any&limit=50&sort=date&psf=advsrch/rc/clk?jk=fc0c274a5d08b523&fccid=c869809b954e0ce1&vjs=3", "Job_Scrape_Date": {"$date": 1540934631394}, "Posted_Days_Ago": "2 hours ago"}}, {"type": "Feature", "geometry": {"type": "Point", "coordinates": [-122.4110835, 37.6304904]}, "properties": {"Website": "Indeed", "Job_Title": "Principal Data Scientist, ECommerce Transportation", "Job_Description": "Position Summary\n\nThe Principal Data Scientist, Transportation, will lead various projects that deliver future operational strategies across Walmart\u2019s e-Commerce Supply Chain. The Principal Data Scientist will be primarily responsible for leading advanced analytical modeling, simulation and optimization projects. He/she will support our strategic plans, both creating and implementing strategic operational improvements to enable expansion of our business\u2019s scope and scale. This role is part of the Walmart eCommerce Transportation Analytics & Network Design team \u2013 a future-focused, action-biased, data-driven team chartered with defining the next generation transportation network by leveraging big data. This is a high-impact and high-visibility role within the organization with expectations to deliver immediate results.\n\nA Principal Data Scientist is responsible for analyzing large data sets, developing custom models and authoring deployable algorithms. Principal Data Scientists typically work within project teams to provide technical and analytical leadership. Principal Data Scientists are often responsible for building large data sets from multiple sources. Principal Data Scientists are also responsible for researching new trends in the industry and utilizing up-to-date technology and analytical methods in their assigned projects.\n\nResponsibilities include:\n\nManage and execute entire projects from start to finish including cross-functional project management, data gathering and manipulation, analysis and modeling, and communication of insights and recommendations.\nDemonstrate a high degree of originality and creativity when developing solutions to improve existing business processes within supply chain utilizing methods such as statistical analysis, regression modeling and optimization.\nWork independently to manage multiple projects at once while ensuring deadlines are met and data output is accurate and appropriate for the business. Must also be able to deal with ambiguity and make independent decisions about what data and approach is best for the task at hand.\nBuild scalable and complex supply chain models and processes to optimize supply chain strategies with goals to deliver excellent customer experience while balancing operating cost and asset efficiency.\nIdentify areas of opportunity and drive results partnering with cross functional partners\nDevelop relationships with Wal-Mart functional areas in San Bruno, CA, as well as in Bentonville, AR, to identify best practices, solicit input/data, coordinate inter-disciplinary initiatives and to gather support for recommendations\nPotential projects can include:\nDevelop optimization logic and tool to determine truckload lane strategy for outbound transportation balancing cost and SLA requirements\nWork at the intersection of Inventory management and Transportation to define the item channel decision and mirroring strategy to drive customer offer and cost\n\nMinimum Qualifications\n\nMasters in Operations Research, Industrial Engineering, Operations Management or Supply Chain Management\n6+ years of post-graduate work experience, including demonstrated success in leading business analysis projects to achieve business-impacting results\nExtensive experience in one or more supply chain domains and related information systems \u2013 distribution/transportation, sourcing, planning, manufacturing and inventory management\nExperience with large data set mining tools and open-source programming tools, (e.g., R, Python, HiveQL, Spark)\nExperience with network modeling tools and network optimization techniques - long range planning is a plus\nExperience with statistical analysis, regression modeling, data mining, financial analysis, and optimization.\nExpert in MS-Excel and SQL\nCompetent in MS-PowerPoint and comfortable building presentation materials to tell a clear story\nAbility to foster successful partnerships within cross-functional teams\nEffective communication skills at multiple levels of the organization, including senior management - ability to communicate complex concepts in easy-to-understand terminology\nAbility to champion ideas and influence the organization with fact-driven recommendations\nStrong follow-through skills and acute attention to detail\nFoster and maintain Walmart's four core values:\nAct with Integrity\nRespect for the Individual\nService to our Customers\nStrive for Excellence\n\nAdditional Preferred Qualifications\n\nPhD in Operations Research, Industrial Engineering, Operations Management or Supply Chain Management\nRetail e-commerce industry experience4 hours ago ", "Company": "Jet.com", "Location": "San Bruno", "Skills_List": ["Excel", "Python", "Masters", "PhD"], "Job_Posting_URL": "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=data+scientist&as_cmp=&jt=all&st=&as_src=&salary=&radius=0&l=CA&fromage=any&limit=50&sort=date&psf=advsrch/rc/clk?jk=98f0cd1c3a763736&fccid=6b4d07f14c1f38ca&vjs=3", "Job_Scrape_Date": {"$date": 1540934634535}, "Posted_Days_Ago": "4 hours ago"}}, {"type": "Feature", "geometry": {"type": "Point", "coordinates": [-122.4194155, 37.7749295]}, "properties": {"Website": "Indeed", "Job_Title": "Data Scientist - Cyber Security", "Job_Description": "Job Description\nExcited by using massive amounts of data to develop machine learning (ML) models for cyber security? Want to help the largest global enterprises operate safely in the cloud and securely derive business value through the adoption of artificial intelligence? Eager to learn from many different enterprise\u2019s use cases of AWS ML and security services? Thrilled to be key part of Amazon, who has been investing in machine learning and cyber security, pioneering and shaping the world\u2019s technology? Our Professional Services organization works together with our AWS customers to address their security needs \u2013 and we are investing in our use of AI, ML, and advanced analytics in this pursuit.\n\nAt AWS, we\u2019re hiring technical specialists at the convergence of the three hottest areas in tech: Data Science, Cyber Security, and Cloud Services. Are we only hiring magical unicorns with depth of skills in all three\u2026? Nope. You\u2019re a great fit for this role if you have hands-on experience in data science and have some exposure to Security or Cloud. We\u2019ll help you grow into a unicorn while you work directly with Amazon\u2019s biggest customers \u2013 leveraging data and analytics to help them find innovative ways to work securely in the cloud.\n\nResponsibilities include:\nExpertise \u2013 Customers using AWS are collecting more data than ever before about their network, infrastructure, services, applications, and users. There is a broad canvas of security-related data waiting to be tapped to help our customers know their information resources and keep them safe. You\u2019re an expert with data \u2013 envisioning scenarios, cleaning data, gaining initial insight, building models, iterating, and bringing action from insight.\nSolutions \u2013 You like working with customers to solve problems and identify opportunities in their security approach and implementation. You\u2019ll define and deliver on-site technical engagements with partners and customers. This includes not only delivering custom solution engagements, but also participating in pre-sales on-site visits, understanding customer security and compliance requirements, evaluating their data and analytics readiness, and proposing and delivering packaged offerings.\nDelivery - Lead the hands-on execution of customer engagements and internal builder projects. Customer engagements include migration of existing functionality, evolution of existing capabilities and process, and development of new applications using AWS cloud services.\nPractice Development \u2013 Helping customers is our number one goal \u2013 but it\u2019s not our only goal. With each engagement, you\u2019re looking for ways to collect, capture, package and share your knowledge with new customers, partners, and AWS employees. You are a force-multiplier \u2013 developing tools, services, and new artifacts to help others build on the work you deliver.\nAmazon aims to be the most customer centric company on earth. Amazon Web Services (AWS) provides a highly reliable, scalable, low-cost infrastructure platform in the cloud that powers critical applications for hundreds of thousands of businesses in 190 countries around the world.\nBasic Qualifications\nEITHER: Bachelor\u2019s Degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics) and 5+ years\u2019 experience in data science and predictive modeling\nOR: Phd/MTech/MS in Computer Science, Artificial Intelligence/Machine Learning, Mathematics or Statistics and 3+ years\u2019 experience in data science and predictive modeling\nExperience using Python and/or R\nPrevious experience in a ML or data scientist role and a track record of building ML or DL models\nAbility to travel to customer sites as needed\nPreferred Qualifications\nExperience manipulating and transforming large datasets \u2013 either on large scale RDBMS or SQL-on-Hadoop technologies such as Hive, Pig, Impala, Spark SQL, and/or Presto.\nExperience with machine learning or statistical libraries: SparkML, scikitlearn, caret, mlr, MLlib\nStrong troubleshooting and problem-solving skills\nEffective communication and strong collaboration skills\nCommercial security solutions such as web application firewalls, IDS/IPS, SIEM, DLP, DDOS mitigation\nExperience automating IT & security tasks\nImplementation experience with enterprise security solutions such as WAF, IPS, Anti-DDOS, and SIEM\nUnderstanding architectural implications of meeting industry standards such as PCI DSS, ISO 27001, HIPAA, and NIST/DoD frameworks9 hours ago ", "Company": "Amazon.com", "Location": "San Francisco", "Skills_List": ["Python", "Machine Learning"], "Job_Posting_URL": "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=data+scientist&as_cmp=&jt=all&st=&as_src=&salary=&radius=0&l=CA&fromage=any&limit=50&sort=date&psf=advsrch/rc/clk?jk=58181e4ddbf06ef1&fccid=fe2d21eef233e94a&vjs=3", "Job_Scrape_Date": {"$date": 1540934637447}, "Posted_Days_Ago": "9 hours ago"}}, {"type": "Feature", "geometry": {"type": "Point", "coordinates": [-119.1770516, 34.1975048]}, "properties": {"Website": "Indeed", "Job_Title": "Senior Data Scientist - California", "Job_Description": "Company Introduction\nOneinaMil is a talent matchmaking firm, we specialize in culture driven recruiting. Our mission is to change the way traditional recruiting is done by putting human connection and culture back into the talent acquisition puzzle. This position is with one of our many fantastic clients. We only work with the best companies out there, so if you are looking to join an amazing company, this could be the opportunity for you!\n\nWhat You'll Do:\n\nYou will have an opportunity for you to use your leadership and analytical skills to improve the Department of Defense and federal agencies.\nYou will work closely with your customer to understand their questions and needs, then dig into their data-rich environment to find the pieces of their information puzzle.\nYou will mentor teammates, develop algorithms, write scripts, build predictive analytics, use automation, and apply machine learning to turn disparate data points into objective answers to help our nation\u2019s services and leaders make data-driven decision.\nYou will provide your customer with a deep understanding of their data, what it all means, and how they can use it.\n\nRequirements:\nWhat You'll Have:\n\nYou have 5+ years of experience with data science and analytics.\nYou have experience with analyzing large data sets.\nYou have experience with programming and scripting languages, including Python.\nYou have the ability to effectively communicate results to technical and non-technical audiences.\nYou have the ability to carry out complex projects in data science and analytics with minimal supervision.\nYou have the ability to be highly motivated for learning.\nYou have the ability to obtain a security clearance.\nYou have a BA or BS degree.\n\nBenefits:\nStunning benefit package!10 hours ago If you require alternative methods of application or screening, you must approach the employer directly to request this as Indeed is not responsible for the employer's application process.", "Company": "OneinaMil", "Location": "Oxnard", "Skills_List": ["Python", "Machine Learning"], "Job_Posting_URL": "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=data+scientist&as_cmp=&jt=all&st=&as_src=&salary=&radius=0&l=CA&fromage=any&limit=50&sort=date&psf=advsrch/rc/clk?jk=46346a26cb11ca5b&fccid=4d4038a17047da58&vjs=3", "Job_Scrape_Date": {"$date": 1540934640642}, "Posted_Days_Ago": "10 hours ago"}}, {"type": "Feature", "geometry": {"type": "Point", "coordinates": [-117.1610838, 32.715738]}, "properties": {"Website": "Indeed", "Job_Title": "Data Scientist", "Job_Description": "Trimble is hiring a Data Scientist in San Diego, CA with strong interests and capabilities in the implementation and design of analytical data models and reports. Our team is focused on driving a culture of experimentation and bold thinking through rapid build/measure/learn cycles. You will be working and coordinating with colleagues who bring engineering, industry domain, business development, design and analytical thinking skill sets to the table, and are dedicated to taking a customer-centric approach to developing innovation,\n\nOur team is focused on supporting the stakeholders of construction projects (architects, interior designers, structural designers and mechanical, electrical & plumbing contractors) who visit our web sites (3D Warehouse, Tekla Warehouse, MEPContent.com, Trade Service and Building Data) to gather information about the products that buildings are made of. Trimble attracts tens of millions of users from around the world who are in need of 2D & 3D CAD files, product pricing information, detailed specifications and a host of other materials that fuel their professional workflows. This content is often published and maintained by building product manufacturers, for whom the distribution of up-to-date product information serves a critical sales and marketing function.\n\nKey Responsibilities:\nPresent intelligible data and analysis reports to cross-functional stakeholders within the organization.\nGather insights about workflows and behavior patterns from qualitative research that will better inform usability data models.\nDetermine user needs by conducting quantitative, task-focused analyses\nDesign and develop relational databases for collecting data\nCollaborate with UI|UX|UER designers to gather and analyze usability test results to create actionable reports.\n\nSkills/Experience Required:\nBachelor's Degree in Data Science, Statistics, Applied Mathematics, Computer Science, Engineering or related field and 6+ years of experience\nExperience modeling, validating, importing, cleaning or transforming data with the purpose of extracting insights for decision making purposes\nThorough understanding of contemporary data gathering, analysis and reporting technologies.\nExperience designing and maintaining GAnalytics implementations for web & mobile products.\nAble to apply strong analytical problem solving skills and creativity. Able to prioritize and execute effectively despite uncertainty.\nPossess a strong work ethic, driven by intrinsic motivators and a strong sense of personal accountability; Is a self-driven professional committed to producing high quality work.\nHas an avid curiosity and desire to discover the what, how and why.\n\nDesired Skills/Experience\n\nExperience with Big Data technology: Hadoop, Hive, Spark, etc.\nExpertise with machine learning packages: Python, R,SAS. etc.\nWorking knowledge of scripting and programming languages: Python, Java, C#, C++. etc.\nExperience with Graph Database technologies: Neo4J, MongoDB, etc.\n\nTrimble is proud to be an Equal Opportunity and Affirmative Action Employer and considers qualified applicants for employment without regard to race, gender, age, color, religion, national origin, marital status, disability, sexual orientation, status as a covered veteran in accordance with applicable federal, state and local laws, or any other protected factor. EOE/M/F/V/D\n#engineering\n\nTrimble Inc. and its affiliate companies consider applicants on the basis of qualifications and without regard to race, color, religion, sex, national origin, age, marital or veteran status, sexual orientation, disability or any other legally protected status.13 hours ago ", "Company": "Trimble Inc.", "Location": "San Diego", "Skills_List": ["Python", "Java", "MongoDB", "Machine Learning", "Bachelors"], "Job_Posting_URL": "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=data+scientist&as_cmp=&jt=all&st=&as_src=&salary=&radius=0&l=CA&fromage=any&limit=50&sort=date&psf=advsrch/rc/clk?jk=657713576abf4002&fccid=3d2456270cbb298b&vjs=3", "Job_Scrape_Date": {"$date": 1540934643670}, "Posted_Days_Ago": "13 hours ago"}}, {"type": "Feature", "geometry": {"type": "Point", "coordinates": [-122.4194155, 37.7749295]}, "properties": {"Website": "Indeed", "Job_Title": "Senior Data Scientist/R Engineer", "Job_Description": "10+ years of experience in Data Science.Good knowledge of R Language.Good Communication skill.Job Type: ContractExperience:Data Science: 9 years (Required)12 hours ago If you require alternative methods of application or screening, you must approach the employer directly to request this as Indeed is not responsible for the employer's application process.", "Company": "Tanisha Systems Inc", "Location": "San Francisco", "Skills_List": ["R"], "Job_Posting_URL": "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=data+scientist&as_cmp=&jt=all&st=&as_src=&salary=&radius=0&l=CA&fromage=any&limit=50&sort=date&psf=advsrch/company/Tanisha-Systems-Inc/jobs/Senior-Data-Scientist-R-Engineer-619885ea8709e48b?fccid=9c4171181b7ea71f&vjs=3", "Job_Scrape_Date": {"$date": 1540934646671}, "Posted_Days_Ago": "12 hours ago"}}];

// Define streetmap and darkmap layers
var streetmap = L.tileLayer("https://api.tiles.mapbox.com/v4/{id}/{z}/{x}/{y}.png?access_token={accessToken}", {
  attribution: "Map data &copy; <a href=\"https://www.openstreetmap.org/\">OpenStreetMap</a> contributors, <a href=\"https://creativecommons.org/licenses/by-sa/2.0/\">CC-BY-SA</a>, Imagery  <a href=\"https://www.mapbox.com/\">Mapbox</a>",
  maxZoom: 18,
  id: "mapbox.streets",
  accessToken: API_KEY
});

var darkmap = L.tileLayer("https://api.tiles.mapbox.com/v4/{id}/{z}/{x}/{y}.png?access_token={accessToken}", {
  attribution: "Map data &copy; <a href=\"https://www.openstreetmap.org/\">OpenStreetMap</a> contributors, <a href=\"https://creativecommons.org/licenses/by-sa/2.0/\">CC-BY-SA</a>, Imagery  <a href=\"https://www.mapbox.com/\">Mapbox</a>",
  maxZoom: 18,
  id: "mapbox.dark",
  accessToken: API_KEY
});

// Define a baseMaps object to hold our base layers
var baseMaps = {
  "Street Map": streetmap,
  "Dark Map": darkmap
};

// Create our map, giving it the streetmap and all jobs layers to display on load
var myMap = L.map("map", {
  center: [
    37.7749295,-122.4194155
  ],
  zoom: 6,
  layers: [streetmap]
});

// creates outline of California using Chloropleth plugin
var caData = statesData.features.filter(d => d.properties.name === 'California');
L.geoJson(caData, {style: {color: 'black'}}).addTo(myMap);

var layerscontrol = L.control.layers(baseMaps).addTo(myMap);

var overlayMaps = {};
var skills_dict;

function generateMap(jobs) {

  // Dictionary that will hold list of jobs pertaining to that skill
  skills_dict = {
    'Excel': [],
    'SQL': [],
    'mySQL': [],
    'Python': [],
    'JavaScript': [],
    'Java': [],
    'pandas': [],
    'html': [],
    'MongoDB': [],
    'CSS': [],
    'Leaflet': [],
    'Numpy': [],
    'VBA': [],
    'd3': [],
    'matplotlib': [],
    'Plotly': [],
    'Tableau': [],
    'Machine Learning': [],
    'R': [],
    'Bachelors': [],
    'Masters': [],
    'PhD': [],
    'Spark': [],
    'Hadoop': []
  }

  // Delete all layers to generate new map
  layerscontrol.remove();
  if (counter > 1) {    
    for (var key in overlayMaps) {
      myMap.removeLayer(overlayMaps[key]);
    }
    overlayMaps = {};
  }

  // for each job, look if each of its skills has a corresponding key in skills_dict
  // if it does, append that job to that key's list
  for(var i = 0; i < jobs.length; i++) {
    var current_skills = jobs[i].properties.Skills_List;

    current_skills.forEach(function(skill) {
      if (skill in skills_dict) {
        skills_dict[skill].push(jobs[i]);
      }
    });
  }

  // Define a function we want to run once for each feature in the features array
  // Give each feature a popup which includes job title, company name and relevant skills
  function onEachFeature(feature, layer) {
    layer.bindPopup("<h3><a href='" + feature.properties.Job_Posting_URL + "'>"+ feature.properties.Job_Title +
      "</a></h3><p>Company: " + feature.properties.Company+ "</p><p>Source: " + feature.properties.Website + "</p><hr><p>Skills: " 
      + feature.properties.Skills_List + "</p>");
  }

  // Create custom marker for each job
  // Documentation: https://github.com/coryasilva/Leaflet.ExtraMarkers
  var redMarker = L.ExtraMarkers.icon({
      icon: 'fa-database',
      markerColor: 'orange-dark',
      shape: 'square',
      prefix: 'fa'
    });

  function pointToLayer(feature, latlng) {
    return L.marker(latlng, {icon: redMarker});
  }

  // Create a geoJSON layer that contains all jobs 
  // (addTo map checks layer by default)
  jobLayer = L.geoJSON(jobs, {
    pointToLayer: pointToLayer,
    onEachFeature: onEachFeature
  }).addTo(myMap);

  overlayMaps["All Jobs"] = jobLayer;

  // Create a geoJSON layer for each language/skill
  for (var key in skills_dict) {
    // Don't create a layer for the skills that have no jobs (i.e. the keys that have an associated empty array value)
    if (skills_dict[key].length !== 0) {
      overlayMaps[`${key} Jobs`] = L.geoJson(skills_dict[key], {
        pointToLayer: pointToLayer,
        onEachFeature: onEachFeature
      });
    }  
  }
  
  // Create a layer control
  // Pass in our baseMaps and overlayMaps
  // Add the layer control to the map
  layerscontrol = L.control.layers(baseMaps, overlayMaps, {
    collapsed: false
  }).addTo(myMap);
}

var counter = 0;
var url;
var currentJob;
var button = d3.selectAll(".job-option");
var icons = {'Indeed': 'https://lh3.googleusercontent.com/H0pHyu8AVpjvQIP6NrSdU0JMEZBnEQ2PO3exWnvR1qckMGJDwhekt-dWKFjWbZlQl4I',
'LinkedIn': 'https://image.flaticon.com/icons/svg/174/174857.svg',
'Monster': 'https://apprecs.org/gp/images/app-icons/300/83/com.monsterindia.seeker.views.jpg'}

// generate a map based on what button was clicked
button.on("click", function() {

  counter = counter + 1; 
  // reset button's style
  button.style("opacity", 1);
  selectedbtn = d3.select(this);

  selectedbtn.style("opacity", 0.5);

  // if user reselects same button, simply do nothing (do not regenerate map)
  if (currentJob === selectedbtn.text()) {
    console.log("We're already here!")
    return;
  // otherwise, set url to endpoint based on what button was selected
  } else {
    currentJob = selectedbtn.text();
    //console.log(currentJob);
    if (currentJob === 'Data Analyst') {
      url = '/leaflet-analyst';
      color = '#2780E3';
    } else if (currentJob === 'Data Scientist') {
      url = '/leaflet-scientist';
      color = '#373a3c';
    }
    
    d3.select("#job-listing").html('');

    d3.json(url, function(data) {
      generateMap(data);
      var totalNumOfJobs = data.length;
    	d3.select("#job-listing").append("div").attr("class","job-container");
    	d3.select(".job-container").append("h1").text(`Displaying 20 of ${totalNumOfJobs} ${currentJob} Jobs`);
	    d3.select(".job-container").selectAll("div")
	      .data(data.slice(0,20))
	      .enter()
	      .append("div")
	      .attr("class", "job-listing")
	      .style("background", color)
	      .html(function(d) {
	        return `<img src='${icons[d.properties.Website]}' class='icon' /><br><h5>${d.properties.Job_Title}</h5><br>${d.properties.Company}`;
	      })
	      .on('mouseover', function() {
	        d3.select(this).style('opacity',0.5);
	      })
	      .on('mouseout', function() {
	        d3.select(this).style('opacity',1);
	      })
	    })   
  }
  })

// Plotly graphs
var ana_url = '/leaflet-analyst' ;
var sci_url = '/leaflet-scientist';
d3.json(ana_url, function(leaflet_analyst) {
	d3.json(sci_url, function(leaflet_scientist) {
		var analyst_skills = [];
		leaflet_analyst.forEach(function(d) {
		  d.properties.Skills_List.forEach(function(subd) {
		    analyst_skills.push(subd);
		  });  
		})

		var scientist_skills = [];
		leaflet_scientist.forEach(function(d) {
		  d.properties.Skills_List.forEach(function(subd) {
		    scientist_skills.push(subd);
		  });  
		})

		var analyst_skill_dict = {
		  'Excel' : 0,
		  'SQL': 0,
		  'mySQL' : 0,
		  'Python': 0,
		  'JavaScript': 0,
		  'Java': 0,
		  'pandas': 0,
		  'html': 0,
		  'MongoDB': 0,
		  'CSS': 0,
		  'Leaflet': 0,
		  'Numpy': 0,
		  'VBA': 0,
		  'd3': 0,
		  'matplotlib': 0,
		  'Tableau': 0,
		  'Machine Learning': 0,
		  'Bachelors': 0,
		  'Masters': 0,
		  'R':0,
		  'PhD':0,
		  'Plotly':0,
		  'Hadoop': 0,
		  'Spark':0
		};

		var scientist_skill_dict = {
		  'Excel' : 0,
		  'SQL': 0,
		  'mySQL' : 0,
		  'Python': 0,
		  'JavaScript': 0,
		  'Java': 0,
		  'pandas': 0,
		  'html': 0,
		  'MongoDB': 0,
		  'CSS': 0,
		  'Leaflet': 0,
		  'Numpy': 0,
		  'VBA': 0,
		  'd3': 0,
		  'matplotlib': 0,
		  'Tableau': 0,
		  'Machine Learning': 0,
		  'R':0,
		  'Bachelors': 0,
		  'Masters': 0,
		  'PhD':0,
		  'Plotly':0,
		  'Hadoop': 0,
		  'Spark': 0
		};

		analyst_skills.forEach(function(element){
		  analyst_skill_dict[element] += 1;
		});

		scientist_skills.forEach(function(element){
		  scientist_skill_dict[element] += 1;
		});

		var analyst_letters = Object.keys(analyst_skill_dict);
		var analyst_counts = Object.values(analyst_skill_dict);

		var scientist_letters = Object.keys(scientist_skill_dict);
		var scientist_counts = Object.values(scientist_skill_dict);

		var trace1 = {
		  x: analyst_letters,
		  y: analyst_counts,
		  type: 'bar',
		  name: "Data Analyst Skills",
		  marker: {
		    color: '#2780E3'
		  }
		};

		var trace2 = {
		  x: scientist_letters,
		  y: scientist_counts,
		  type: 'bar',
		  name: "Data Scientist Skills",
		  marker: {
		    color: '#2d3436'
		  }
		};

		var layout = {
		  barmode: 'group'
		};

		var combined_data = [trace1, trace2];
		Plotly.newPlot('com-plot', combined_data, layout);

		var analyst_sorted = [];
		for (var analyst_skill in analyst_skill_dict) {
		  analyst_sorted.push([analyst_skill, analyst_skill_dict[analyst_skill]]);
		}
		analyst_sorted.sort(function(a, b) {
		    return b[1] - a[1];
		});

		var analyst_x = [];
		var analyst_y = [];

		analyst_sorted.forEach(function(el) {
		  if (el[1] !== 0) {
		    analyst_x.push(el[0]);
		    analyst_y.push(el[1]);
		  }
		  
		})

		var analyst_trace = {
		  x: analyst_x,
		  y: analyst_y,
		  type: 'bar',
		  marker: {
		    color: '#2780E3'
		  }
		}

		var analyst_layout = {
		  title: 'Top Data Analyst Skills',
		  bargap: 0.05
		}
		var analyst_data = [analyst_trace];
		Plotly.newPlot('ana-plot',analyst_data ,analyst_layout);

		var scientist_sorted = [];
		for (var scientist_skill in scientist_skill_dict) {
		  scientist_sorted.push([scientist_skill, scientist_skill_dict[scientist_skill]]);
		}
		scientist_sorted.sort(function(a, b) {
		    return b[1] - a[1];
		});

		var scientist_x = [];
		var scientist_y = [];

		scientist_sorted.forEach(function(el) {
		  if (el[1] !== 0) {
		    scientist_x.push(el[0]);
		    scientist_y.push(el[1]);
		  }
		})

		var scientist_trace = {
		  x: scientist_x,
		  y: scientist_y,
		  type: 'bar',
		  marker: {
		    color: '#2d3436'
		  }
		}

		var scientist_layout = {
		  title: 'Top Data Scientist Skills',
		  bargap: 0.05
		}

		var scientist_data = [scientist_trace];
		Plotly.newPlot('sci-plot',scientist_data, scientist_layout);


	})
});



